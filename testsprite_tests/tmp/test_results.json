[
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "0f204239-0dc0-4ff0-a01f-5ebcffc88da3",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC001-valid pdf upload and metadata extraction",
    "description": "Test uploading a valid PDF file to the /extract-metadata endpoint and verify successful extraction of legal metadata including appellant, respondent, judgeName, judgementType, caseResult, caseNumber, courtName, dateOfJudgement, and referredCases.",
    "code": "import requests\nimport os\n\nBASE_URL = \"http://localhost:3000\"\nENDPOINT = \"/extract-metadata\"\nTIMEOUT = 30\n\nTEST_FILES_DIR = \"testsprite_tests/test_files\"\nTEST_FILES = [\n    \"anita_yuvraj_test.pdf\",\n    \"Tej Karan - Jodhpur.pdf\",\n    # Add other available PDF files in the directory for extended testing\n]\n\ndef test_valid_pdf_upload_and_metadata_extraction():\n    url = BASE_URL + ENDPOINT\n    headers = {}\n    for filename in TEST_FILES:\n        file_path = os.path.join(TEST_FILES_DIR, filename)\n        assert os.path.isfile(file_path), f\"Test file not found: {file_path}\"\n        with open(file_path, \"rb\") as pdf_file:\n            files = {\"pdf\": (filename, pdf_file, \"application/pdf\")}\n            try:\n                response = requests.post(url, files=files, headers=headers, timeout=TIMEOUT)\n            except requests.RequestException as e:\n                assert False, f\"Request failed for file {filename}: {e}\"\n            assert response.status_code == 200, f\"Unexpected status code {response.status_code} for file {filename}\"\n            try:\n                json_resp = response.json()\n            except ValueError:\n                assert False, f\"Response is not valid JSON for file {filename}\"\n            # Validate success flag\n            assert \"success\" in json_resp, f\"'success' field missing in response for file {filename}\"\n            assert json_resp[\"success\"] is True, f\"Extraction not successful for file {filename}\"\n            # Validate metadata presence and types\n            metadata = json_resp.get(\"metadata\")\n            assert metadata is not None, f\"'metadata' missing in response for file {filename}\"\n            required_fields = [\n                \"appellant\",\n                \"respondent\",\n                \"judgeName\",\n                \"judgementType\",\n                \"caseResult\",\n                \"caseNumber\",\n                \"courtName\",\n                \"dateOfJudgement\",\n                \"referredCases\",\n            ]\n            for field in required_fields:\n                assert field in metadata, f\"Metadata field '{field}' missing for file {filename}\"\n            # Validate types\n            assert isinstance(metadata[\"appellant\"], str), f\"Field 'appellant' is not string for file {filename}\"\n            assert isinstance(metadata[\"respondent\"], str), f\"Field 'respondent' is not string for file {filename}\"\n            assert isinstance(metadata[\"judgeName\"], str), f\"Field 'judgeName' is not string for file {filename}\"\n            assert isinstance(metadata[\"judgementType\"], str), f\"Field 'judgementType' is not string for file {filename}\"\n            assert isinstance(metadata[\"caseResult\"], str), f\"Field 'caseResult' is not string for file {filename}\"\n            assert isinstance(metadata[\"caseNumber\"], str), f\"Field 'caseNumber' is not string for file {filename}\"\n            assert isinstance(metadata[\"courtName\"], str), f\"Field 'courtName' is not string for file {filename}\"\n            assert isinstance(metadata[\"dateOfJudgement\"], str), f\"Field 'dateOfJudgement' is not string for file {filename}\"\n            assert isinstance(metadata[\"referredCases\"], list), f\"Field 'referredCases' is not list for file {filename}\"\n            # Validate fileInfo presence and types\n            file_info = json_resp.get(\"fileInfo\")\n            assert file_info is not None, f\"'fileInfo' missing in response for file {filename}\"\n            assert isinstance(file_info.get(\"originalName\"), str), f\"'originalName' missing or not string for file {filename}\"\n            assert isinstance(file_info.get(\"fileSize\"), (int, float)), f\"'fileSize' missing or not number for file {filename}\"\n            assert isinstance(file_info.get(\"uploadTime\"), str), f\"'uploadTime' missing or not string for file {filename}\"\n            # Validate processingInfo presence and types\n            processing_info = json_resp.get(\"processingInfo\")\n            assert processing_info is not None, f\"'processingInfo' missing in response for file {filename}\"\n            assert isinstance(processing_info.get(\"extractionMethod\"), str), f\"'extractionMethod' missing or not string for file {filename}\"\n            confidence = processing_info.get(\"confidence\")\n            assert isinstance(confidence, (int, float)), f\"'confidence' missing or not number for file {filename}\"\n            assert 0.0 <= confidence <= 1.0, f\"'confidence' out of range [0,1] for file {filename}\"\n            assert isinstance(processing_info.get(\"isScanned\"), bool), f\"'isScanned' missing or not boolean for file {filename}\"\n            page_count = processing_info.get(\"pageCount\")\n            assert isinstance(page_count, int), f\"'pageCount' missing or not int for file {filename}\"\n            assert page_count > 0, f\"'pageCount' should be positive for file {filename}\"\n\ntest_valid_pdf_upload_and_metadata_extraction()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 79, in <module>\n  File \"<string>\", line 20, in test_valid_pdf_upload_and_metadata_extraction\nAssertionError: Test file not found: testsprite_tests/test_files/anita_yuvraj_test.pdf\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.912Z",
    "modified": "2025-07-28T11:08:17.296Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "dba09555-b706-4db1-9540-d6e40cb68bdc",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC002-invalid file type rejection on metadata extraction",
    "description": "Test uploading a non-PDF file to the /extract-metadata endpoint and verify that the system rejects the file with an appropriate error message indicating invalid file type.",
    "code": "import requests\n\ndef test_invalid_file_type_rejection_on_metadata_extraction():\n    url = \"http://localhost:3000/extract-metadata\"\n    # Use a non-PDF file for testing - a simple text file created on the fly\n    # Since no specific non-PDF file path is given, create a small in-memory file\n    non_pdf_content = b\"This is a test text file, not a PDF.\"\n    files = {\n        \"pdf\": (\"test.txt\", non_pdf_content, \"text/plain\")\n    }\n    try:\n        response = requests.post(url, files=files, timeout=30)\n    except requests.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\n    # Expecting a rejection due to invalid file type\n    assert response.status_code in (400, 415), f\"Expected 400 or 415 status code, got {response.status_code}\"\n    try:\n        json_resp = response.json()\n    except ValueError:\n        assert False, \"Response is not valid JSON\"\n\n    # The response should indicate failure and mention invalid file type\n    assert \"success\" in json_resp, \"Response JSON missing 'success' field\"\n    assert json_resp[\"success\"] is False, \"Expected success to be False for invalid file type\"\n    error_msg = json_resp.get(\"error\") or json_resp.get(\"message\") or \"\"\n    assert any(keyword in error_msg.lower() for keyword in [\"invalid file type\", \"unsupported file type\", \"file type\"]), \\\n        f\"Error message does not indicate invalid file type: {error_msg}\"\n\ntest_invalid_file_type_rejection_on_metadata_extraction()",
    "testStatus": "PASSED",
    "testError": "",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.918Z",
    "modified": "2025-07-28T11:08:14.864Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "0c91a8f8-1f25-4700-a8b0-3ba6196d898d",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC003-large file size handling on metadata extraction",
    "description": "Test uploading a PDF file close to the 50MB size limit to the /extract-metadata endpoint and verify that the system processes the file correctly without errors or performance degradation.",
    "code": "import os\nimport time\nimport requests\n\nBASE_URL = \"http://localhost:3000\"\nEXTRACT_METADATA_ENDPOINT = \"/extract-metadata\"\nTIMEOUT = 30\n\ndef test_large_file_size_handling_on_metadata_extraction():\n    # Files to test - large PDFs close to 50MB if available\n    test_files = [\n        \"testsprite_tests/test_files/Tej Karan - Jodhpur.pdf\",\n        \"testsprite_tests/test_files/anita_yuvraj_test.pdf\",\n        \"testsprite_tests/test_files/Ravinder Kaur - UK.pdf\"\n    ]\n\n    for file_path in test_files:\n        assert os.path.isfile(file_path), f\"Test file not found: {file_path}\"\n        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n        assert file_size_mb <= 50, f\"Test file {file_path} exceeds 50MB limit\"\n\n        with open(file_path, \"rb\") as f:\n            files = {\"pdf\": (os.path.basename(file_path), f, \"application/pdf\")}\n            try:\n                start_time = time.time()\n                response = requests.post(\n                    BASE_URL + EXTRACT_METADATA_ENDPOINT,\n                    files=files,\n                    timeout=TIMEOUT\n                )\n                duration = time.time() - start_time\n            except requests.RequestException as e:\n                assert False, f\"Request failed for {file_path}: {e}\"\n\n        assert response.status_code == 200, f\"Unexpected status code {response.status_code} for file {file_path}\"\n        try:\n            json_resp = response.json()\n        except Exception as e:\n            assert False, f\"Response is not valid JSON for file {file_path}: {e}\"\n\n        # Validate response schema and content\n        assert \"success\" in json_resp, f\"'success' field missing in response for file {file_path}\"\n        assert json_resp[\"success\"] is True, f\"Extraction failed for file {file_path}\"\n\n        metadata = json_resp.get(\"metadata\")\n        file_info = json_resp.get(\"fileInfo\")\n        processing_info = json_resp.get(\"processingInfo\")\n\n        # Validate metadata fields presence and types\n        expected_metadata_fields = [\n            \"appellant\", \"respondent\", \"judgeName\", \"judgementType\",\n            \"caseResult\", \"caseNumber\", \"courtName\", \"dateOfJudgement\", \"referredCases\"\n        ]\n        assert isinstance(metadata, dict), f\"'metadata' is not a dict for file {file_path}\"\n        for field in expected_metadata_fields:\n            assert field in metadata, f\"Metadata field '{field}' missing for file {file_path}\"\n        assert isinstance(metadata[\"referredCases\"], list), f\"'referredCases' is not a list for file {file_path}\"\n\n        # Validate fileInfo fields\n        assert isinstance(file_info, dict), f\"'fileInfo' is not a dict for file {file_path}\"\n        assert file_info.get(\"originalName\") == os.path.basename(file_path), f\"originalName mismatch for file {file_path}\"\n        assert isinstance(file_info.get(\"fileSize\"), (int, float)), f\"fileSize invalid type for file {file_path}\"\n        assert file_info.get(\"fileSize\") > 0, f\"fileSize should be positive for file {file_path}\"\n        assert isinstance(file_info.get(\"uploadTime\"), str), f\"uploadTime invalid type for file {file_path}\"\n\n        # Validate processingInfo fields\n        assert isinstance(processing_info, dict), f\"'processingInfo' is not a dict for file {file_path}\"\n        assert isinstance(processing_info.get(\"extractionMethod\"), str), f\"extractionMethod invalid type for file {file_path}\"\n        confidence = processing_info.get(\"confidence\")\n        assert isinstance(confidence, (int, float)), f\"confidence invalid type for file {file_path}\"\n        assert 0 <= confidence <= 1, f\"confidence out of range for file {file_path}\"\n        assert isinstance(processing_info.get(\"isScanned\"), bool), f\"isScanned invalid type for file {file_path}\"\n        page_count = processing_info.get(\"pageCount\")\n        assert isinstance(page_count, int), f\"pageCount invalid type for file {file_path}\"\n        assert page_count > 0, f\"pageCount should be positive for file {file_path}\"\n\n        # Performance check: response time should be under 30 seconds as per NFR\n        assert duration < 30, f\"Response time {duration}s exceeded 30 seconds for file {file_path}\"\n\ntest_large_file_size_handling_on_metadata_extraction()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 80, in <module>\n  File \"<string>\", line 18, in test_large_file_size_handling_on_metadata_extraction\nAssertionError: Test file not found: testsprite_tests/test_files/Tej Karan - Jodhpur.pdf\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.925Z",
    "modified": "2025-07-28T11:08:17.147Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "9d304c51-d26d-4fdb-87ef-6530865b5f10",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC004-scanned document processing with ocr",
    "description": "Test uploading a scanned PDF document to the /extract-metadata endpoint and verify that the system uses OCR (optionally with tesseract_path) to extract metadata accurately.",
    "code": "import requests\nimport os\n\ndef test_scanned_document_processing_with_ocr():\n    base_url = \"http://localhost:3000\"\n    endpoint = \"/extract-metadata\"\n    url = base_url + endpoint\n    test_file_path = \"testsprite_tests/test_files/Ravinder Kaur - UK.pdf\"\n    tesseract_path = None  # Optionally set this if known, e.g. \"/usr/bin/tesseract\"\n\n    if not os.path.isfile(test_file_path):\n        raise FileNotFoundError(f\"Test file not found: {test_file_path}\")\n\n    params = {}\n    if tesseract_path:\n        params['tesseract_path'] = tesseract_path\n\n    with open(test_file_path, \"rb\") as pdf_file:\n        files = {\n            \"pdf\": (os.path.basename(test_file_path), pdf_file, \"application/pdf\")\n        }\n        try:\n            response = requests.post(url, files=files, params=params, timeout=30)\n            response.raise_for_status()\n        except requests.RequestException as e:\n            assert False, f\"Request failed: {e}\"\n\n    try:\n        json_resp = response.json()\n    except ValueError:\n        assert False, \"Response is not valid JSON\"\n\n    # Validate top-level success flag\n    assert \"success\" in json_resp, \"Response missing 'success' field\"\n    assert json_resp[\"success\"] is True, \"Extraction was not successful\"\n\n    # Validate metadata presence and types\n    metadata = json_resp.get(\"metadata\")\n    assert metadata is not None, \"Response missing 'metadata' field\"\n    expected_metadata_fields = [\n        \"appellant\", \"respondent\", \"judgeName\", \"judgementType\",\n        \"caseResult\", \"caseNumber\", \"courtName\", \"dateOfJudgement\", \"referredCases\"\n    ]\n    for field in expected_metadata_fields:\n        assert field in metadata, f\"Metadata missing field '{field}'\"\n    # referredCases should be a list\n    assert isinstance(metadata[\"referredCases\"], list), \"'referredCases' should be a list\"\n\n    # Validate fileInfo presence and types\n    file_info = json_resp.get(\"fileInfo\")\n    assert file_info is not None, \"Response missing 'fileInfo' field\"\n    assert \"originalName\" in file_info and isinstance(file_info[\"originalName\"], str), \"'fileInfo.originalName' missing or not string\"\n    assert \"fileSize\" in file_info and isinstance(file_info[\"fileSize\"], (int, float)), \"'fileInfo.fileSize' missing or not number\"\n    assert \"uploadTime\" in file_info and isinstance(file_info[\"uploadTime\"], str), \"'fileInfo.uploadTime' missing or not string\"\n\n    # Validate processingInfo presence and types\n    processing_info = json_resp.get(\"processingInfo\")\n    assert processing_info is not None, \"Response missing 'processingInfo' field\"\n    assert \"extractionMethod\" in processing_info and isinstance(processing_info[\"extractionMethod\"], str), \"'processingInfo.extractionMethod' missing or not string\"\n    assert \"confidence\" in processing_info and isinstance(processing_info[\"confidence\"], (int, float)), \"'processingInfo.confidence' missing or not number\"\n    assert \"isScanned\" in processing_info and isinstance(processing_info[\"isScanned\"], bool), \"'processingInfo.isScanned' missing or not boolean\"\n    assert \"pageCount\" in processing_info and isinstance(processing_info[\"pageCount\"], (int, float)), \"'processingInfo.pageCount' missing or not number\"\n\n    # Specifically check that OCR was used for scanned document\n    assert processing_info[\"isScanned\"] is True, \"Document is not marked as scanned\"\n    # extractionMethod should indicate OCR usage (e.g. contain 'OCR' or 'ocr')\n    assert \"ocr\" in processing_info[\"extractionMethod\"].lower(), \"Extraction method does not indicate OCR usage\"\n\n    # Confidence should be a reasonable number between 0 and 1\n    confidence = processing_info[\"confidence\"]\n    assert 0.0 <= confidence <= 1.0, f\"Confidence value out of range: {confidence}\"\n\ntest_scanned_document_processing_with_ocr()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 73, in <module>\n  File \"<string>\", line 12, in test_scanned_document_processing_with_ocr\nFileNotFoundError: Test file not found: testsprite_tests/test_files/Ravinder Kaur - UK.pdf\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.931Z",
    "modified": "2025-07-28T11:08:16.461Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "7a60ec68-eb65-4c64-b19a-916bf25f79b6",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC005-ai extraction fallback to regex",
    "description": "Simulate AI extraction failure on the /extract-metadata endpoint and verify that the system falls back to regex-based extraction to retrieve metadata.",
    "code": "import requests\nimport os\n\nBASE_URL = \"http://localhost:3000\"\nEXTRACT_METADATA_ENDPOINT = \"/extract-metadata\"\nTIMEOUT = 30\n\n# Files to test AI extraction fallback to regex\nTEST_FILES = [\n    \"testsprite_tests/test_files/file-1752733837504-630102423.pdf\",\n    \"testsprite_tests/test_files/pdf-1752741187792-923217221.pdf\"\n]\n\ndef test_ai_extraction_fallback_to_regex():\n    for file_path in TEST_FILES:\n        assert os.path.isfile(file_path), f\"Test file not found: {file_path}\"\n        with open(file_path, \"rb\") as pdf_file:\n            files = {\"pdf\": (os.path.basename(file_path), pdf_file, \"application/pdf\")}\n            try:\n                response = requests.post(\n                    BASE_URL + EXTRACT_METADATA_ENDPOINT,\n                    files=files,\n                    timeout=TIMEOUT\n                )\n            except requests.RequestException as e:\n                assert False, f\"Request failed for {file_path}: {e}\"\n\n            assert response.status_code == 200, f\"Unexpected status code {response.status_code} for {file_path}\"\n            try:\n                data = response.json()\n            except ValueError:\n                assert False, f\"Response is not valid JSON for {file_path}\"\n\n            # Validate response schema basics\n            assert \"success\" in data, f\"'success' field missing in response for {file_path}\"\n            assert isinstance(data[\"success\"], bool), f\"'success' field is not boolean for {file_path}\"\n            assert \"metadata\" in data, f\"'metadata' field missing in response for {file_path}\"\n            assert isinstance(data[\"metadata\"], dict), f\"'metadata' field is not a dict for {file_path}\"\n            assert \"processingInfo\" in data, f\"'processingInfo' field missing in response for {file_path}\"\n            assert isinstance(data[\"processingInfo\"], dict), f\"'processingInfo' field is not a dict for {file_path}\"\n\n            # Check fallback extraction method\n            extraction_method = data[\"processingInfo\"].get(\"extractionMethod\", \"\").lower()\n            # We expect either 'regex' or fallback indicator if AI failed\n            assert extraction_method in (\"regex\", \"ai-failed-regex-fallback\", \"fallback-regex\"), (\n                f\"Extraction method is not fallback regex for {file_path}, got '{extraction_method}'\"\n            )\n\n            # Check that metadata fields are present (may be empty strings if extraction partially failed)\n            metadata = data[\"metadata\"]\n            expected_fields = [\n                \"appellant\", \"respondent\", \"judgeName\", \"judgementType\",\n                \"caseResult\", \"caseNumber\", \"courtName\", \"dateOfJudgement\", \"referredCases\"\n            ]\n            for field in expected_fields:\n                assert field in metadata, f\"Metadata field '{field}' missing for {file_path}\"\n            # referredCases should be a list\n            assert isinstance(metadata.get(\"referredCases\", []), list), f\"'referredCases' is not a list for {file_path}\"\n\n            # Additional checks: confidence should be a number, isScanned boolean, pageCount number\n            processing_info = data[\"processingInfo\"]\n            assert isinstance(processing_info.get(\"confidence\", None), (int, float)), f\"'confidence' not a number for {file_path}\"\n            assert isinstance(processing_info.get(\"isScanned\", None), bool), f\"'isScanned' not a boolean for {file_path}\"\n            assert isinstance(processing_info.get(\"pageCount\", None), int), f\"'pageCount' not an int for {file_path}\"\n\ntest_ai_extraction_fallback_to_regex()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 66, in <module>\n  File \"<string>\", line 16, in test_ai_extraction_fallback_to_regex\nAssertionError: Test file not found: testsprite_tests/test_files/file-1752733837504-630102423.pdf\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.937Z",
    "modified": "2025-07-28T11:08:16.133Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "23cc1022-8017-47de-afdb-2c8c56a56bdc",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC006-rate limiting enforcement",
    "description": "Test sending more than 100 requests per minute to any endpoint and verify that the system enforces rate limiting and returns appropriate error responses.",
    "code": "import requests\nimport time\nimport os\n\nBASE_URL = \"http://localhost:3000\"\nEXTRACT_METADATA_ENDPOINT = \"/extract-metadata\"\nTEST_FILES_DIR = \"testsprite_tests/test_files\"\nTEST_FILES = [\n    \"anita_yuvraj_test.pdf\",\n    \"Tej Karan - Jodhpur.pdf\",\n    \"Ravinder Kaur - UK.pdf\",\n    \"file-1752733837504-630102423.pdf\",\n    \"pdf-1752741187792-923217221.pdf\"\n]\n\ndef test_rate_limiting_enforcement():\n    url = BASE_URL + EXTRACT_METADATA_ENDPOINT\n    headers = {}\n    timeout = 30\n    files = []\n    # Prepare file handles for all test files to cycle through\n    file_handles = []\n    try:\n        for filename in TEST_FILES:\n            path = os.path.join(TEST_FILES_DIR, filename)\n            f = open(path, \"rb\")\n            file_handles.append(f)\n        # We will send 105 requests in quick succession to trigger rate limiting\n        # Cycle through the files to simulate realistic usage\n        total_requests = 105\n        rate_limit_exceeded = False\n        rate_limit_status_codes = {429}\n        rate_limit_error_messages = []\n        for i in range(total_requests):\n            file_index = i % len(file_handles)\n            f = file_handles[file_index]\n            f.seek(0)\n            files = {\"pdf\": (os.path.basename(f.name), f, \"application/pdf\")}\n            try:\n                response = requests.post(url, files=files, headers=headers, timeout=timeout)\n            except requests.RequestException as e:\n                # Network or other request error, fail the test\n                assert False, f\"Request failed with exception: {e}\"\n            if response.status_code in rate_limit_status_codes:\n                rate_limit_exceeded = True\n                try:\n                    json_resp = response.json()\n                    if \"error\" in json_resp:\n                        rate_limit_error_messages.append(json_resp[\"error\"])\n                    elif \"message\" in json_resp:\n                        rate_limit_error_messages.append(json_resp[\"message\"])\n                except Exception:\n                    # Response not JSON or no error message\n                    pass\n            else:\n                # For non-rate limited responses, expect success or valid error codes (e.g. 200 or 4xx)\n                assert response.status_code in (200, 400, 422), f\"Unexpected status code {response.status_code} on request {i+1}\"\n        assert rate_limit_exceeded, \"Rate limiting was not enforced after sending more than 100 requests per minute\"\n        # Optionally check that error messages are meaningful\n        assert any(rate_limit_error_messages), \"Rate limit error responses did not contain error messages\"\n    finally:\n        for f in file_handles:\n            f.close()\n\ntest_rate_limiting_enforcement()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 65, in <module>\n  File \"<string>\", line 26, in test_rate_limiting_enforcement\nFileNotFoundError: [Errno 2] No such file or directory: 'testsprite_tests/test_files/anita_yuvraj_test.pdf'\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.942Z",
    "modified": "2025-07-28T11:08:16.897Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "39f2cb9a-9fec-47b5-96d6-6c0111840ccf",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC007-error handling for extraction endpoint",
    "description": "Test various error scenarios on the /extract-metadata endpoint such as missing required fields, corrupted PDF files, and invalid query parameters, and verify graceful error handling with meaningful messages.",
    "code": "import requests\nimport os\n\nBASE_URL = \"http://localhost:3000\"\nEXTRACT_ENDPOINT = \"/extract-metadata\"\nTIMEOUT = 30\n\ndef test_error_handling_extraction_endpoint():\n    # 1. Missing required 'pdf' field\n    response = requests.post(f\"{BASE_URL}{EXTRACT_ENDPOINT}\", files={}, timeout=TIMEOUT)\n    assert response.status_code == 400 or response.status_code == 422, f\"Expected 400/422 for missing file, got {response.status_code}\"\n    json_resp = response.json()\n    assert not json_resp.get(\"success\", True)\n    assert \"pdf\" in str(json_resp).lower() or \"required\" in str(json_resp).lower()\n\n    # 2. Corrupted PDF file upload\n    corrupted_pdf_path = \"testsprite_tests/test_files/corrupted.pdf\"\n    # Skip creation of corrupted PDF to avoid read-only filesystem issues\n    if os.path.exists(corrupted_pdf_path):\n        with open(corrupted_pdf_path, \"rb\") as corrupted_file:\n            files = {\"pdf\": (\"corrupted.pdf\", corrupted_file, \"application/pdf\")}\n            response = requests.post(f\"{BASE_URL}{EXTRACT_ENDPOINT}\", files=files, timeout=TIMEOUT)\n            assert response.status_code in (400, 422, 500), f\"Expected error status for corrupted PDF, got {response.status_code}\"\n            try:\n                json_resp = response.json()\n                assert not json_resp.get(\"success\", True)\n                assert any(term in str(json_resp).lower() for term in [\"error\", \"corrupt\", \"invalid\", \"failed\"])\n            except Exception:\n                # If response is not JSON, still consider error handled gracefully\n                pass\n\n    # 3. Invalid query parameter 'tesseract_path' (e.g. invalid path type)\n    valid_pdf_path = \"testsprite_tests/test_files/anita_yuvraj_test.pdf\"\n    if not os.path.exists(valid_pdf_path):\n        raise FileNotFoundError(f\"Required test file missing: {valid_pdf_path}\")\n\n    with open(valid_pdf_path, \"rb\") as valid_pdf:\n        files = {\"pdf\": (\"anita_yuvraj_test.pdf\", valid_pdf, \"application/pdf\")}\n        params = {\"tesseract_path\": \"/invalid/path/to/tesseract_executable_that_does_not_exist\"}\n        response = requests.post(f\"{BASE_URL}{EXTRACT_ENDPOINT}\", files=files, params=params, timeout=TIMEOUT)\n        # The system should handle invalid tesseract_path gracefully, either ignoring or returning a meaningful error\n        assert response.status_code in (200, 400, 422), f\"Unexpected status code for invalid tesseract_path: {response.status_code}\"\n        try:\n            json_resp = response.json()\n            # If success true, fallback or ignore invalid path is accepted\n            if json_resp.get(\"success\", False):\n                # Validate presence of expected metadata keys\n                metadata = json_resp.get(\"metadata\", {})\n                assert isinstance(metadata, dict)\n            else:\n                # If error, check for meaningful message about tesseract_path or OCR failure\n                assert any(term in str(json_resp).lower() for term in [\"tesseract\", \"path\", \"invalid\", \"error\", \"ocr\"])\n        except Exception:\n            assert False, \"Response is not valid JSON\"\n\n    # 4. Invalid query parameter (unexpected parameter)\n    with open(valid_pdf_path, \"rb\") as valid_pdf:\n        files = {\"pdf\": (\"anita_yuvraj_test.pdf\", valid_pdf, \"application/pdf\")}\n        params = {\"invalid_param\": \"some_value\"}\n        response = requests.post(f\"{BASE_URL}{EXTRACT_ENDPOINT}\", files=files, params=params, timeout=TIMEOUT)\n        # The system should ignore unknown query params or return a warning/error gracefully\n        assert response.status_code in (200, 400, 422), f\"Unexpected status code for invalid query param: {response.status_code}\"\n        try:\n            json_resp = response.json()\n            # If success true, unknown params ignored\n            if json_resp.get(\"success\", False):\n                metadata = json_resp.get(\"metadata\", {})\n                assert isinstance(metadata, dict)\n            else:\n                # If error, message should mention invalid parameter or similar\n                assert any(term in str(json_resp).lower() for term in [\"invalid\", \"unknown\", \"parameter\", \"error\"])\n        except Exception:\n            assert False, \"Response is not valid JSON\"\n\ntest_error_handling_extraction_endpoint()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 75, in <module>\n  File \"<string>\", line 35, in test_error_handling_extraction_endpoint\nFileNotFoundError: Required test file missing: testsprite_tests/test_files/anita_yuvraj_test.pdf\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.948Z",
    "modified": "2025-07-28T11:08:48.510Z"
  },
  {
    "projectId": "576071e8-cdf5-41d8-b1bc-87e57b1ef7d8",
    "testId": "4622dd66-a46b-469b-bd9e-407a5ceb6b1c",
    "userId": "a438c468-60e1-706c-a71c-28a58a81cfd6",
    "title": "TC008-pdf to docx conversion success",
    "description": "Test uploading a valid PDF file to the /generate-docx endpoint and verify successful conversion to DOCX format with header and footer removed, and correct file download response.",
    "code": "import requests\nimport os\n\nBASE_URL = \"http://localhost:3000\"\nENDPOINT = \"/generate-docx\"\nTIMEOUT = 30\nTEST_FILE_PATH = \"testsprite_tests/test_files/anita_yuvraj_test.pdf\"\n\ndef test_pdf_to_docx_conversion_success():\n    url = BASE_URL + ENDPOINT\n    headers = {}\n    try:\n        with open(TEST_FILE_PATH, \"rb\") as pdf_file:\n            files = {\"pdf\": (os.path.basename(TEST_FILE_PATH), pdf_file, \"application/pdf\")}\n            response = requests.post(url, files=files, headers=headers, timeout=TIMEOUT)\n        # Validate response status code\n        assert response.status_code == 200, f\"Expected status code 200, got {response.status_code}\"\n        # Validate content-type header for DOCX\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        expected_content_type = \"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n        assert content_type == expected_content_type, f\"Expected Content-Type '{expected_content_type}', got '{content_type}'\"\n        # Validate content-disposition header for attachment with .docx filename\n        content_disposition = response.headers.get(\"Content-Disposition\", \"\")\n        assert \"attachment\" in content_disposition.lower(), \"Content-Disposition header missing 'attachment'\"\n        assert content_disposition.lower().endswith(\".docx\\\"\") or \".docx\" in content_disposition.lower(), \"Content-Disposition header missing .docx filename\"\n        # Validate response content is not empty\n        assert response.content and len(response.content) > 0, \"Response content is empty\"\n        # Additional heuristic: DOCX files are ZIP archives, check first 2 bytes for PK signature\n        assert response.content[:2] == b\"PK\", \"Response content does not start with PK signature, likely not a DOCX file\"\n    except requests.exceptions.RequestException as e:\n        assert False, f\"Request failed: {e}\"\n\ntest_pdf_to_docx_conversion_success()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 33, in <module>\n  File \"<string>\", line 13, in test_pdf_to_docx_conversion_success\nFileNotFoundError: [Errno 2] No such file or directory: 'testsprite_tests/test_files/anita_yuvraj_test.pdf'\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-07-28T11:07:49.954Z",
    "modified": "2025-07-28T11:08:17.361Z"
  }
]
